{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNL/lPq1dJj10/YWoEkOD8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfazio/crewAI-quickstart/blob/main/crewai_sequential_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# crewai-sequential-quickstart\n",
        "By [Alex Fazio](https://www.linkedin.com/in/alxfazio)\n",
        "\n",
        "Github repo: https://github.com/alexfazio/crewai-quickstart\n",
        "\n",
        "Docs: https://docs.crewai.com/\n",
        "\n",
        "Simplified and tested version of a **sequential** CrewAI."
      ],
      "metadata": {
        "id": "ANCxcFs-qVl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚¨áÔ∏è Install project dependencies by running this cell\n",
        "!pip install git+https://github.com/joaomdmoura/crewAI.git\n",
        "!pip install langchain_community langchain_groq langchain_anthropic"
      ],
      "metadata": {
        "id": "P8iHNKCfk9Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhAt-unGk4kA"
      },
      "outputs": [],
      "source": [
        "# @title üîë Input API Key by running this cell\n",
        "import os\n",
        "from getpass import getpass\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from textwrap import dedent\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "# from langchain_groq import ChatGroq\n",
        "# ‚Üë uncomment to use Groq's API\n",
        "# from langchain_anthropic import ChatAnthropic\n",
        "# ‚Üë uncomment to use Antrhopic's API\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY: \")\n",
        "# ‚Üë uncomment to use OpenAI's API\n",
        "# os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter GROQ_API_KEY: \")\n",
        "# ‚Üë uncomment to use Groq's API\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Enter ANTHROPIC_API_KEY: \")\n",
        "# ‚Üë uncomment to use Anthropic's API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚å®Ô∏è Define any variables you have and input them\n",
        "print(\"## Welcome to the YOUR_CREW_NAME\")\n",
        "print('-------------------------------------------')\n",
        "var_1 = input(dedent((\n",
        "    f\"\"\"What is the <var_1> to pass to your crew?\\n\n",
        "    \"\"\"))),\n",
        "var_2 = input(dedent((\n",
        "    f\"\"\"What is the <var_1> to pass to your crew?\\n\n",
        "    \"\"\"))),\n",
        "var_3 = input(dedent((\n",
        "    f\"\"\"What is the <var_1> to pass to your crew?\\n\n",
        "    \"\"\"))),\n",
        "print(\"-------------------------------\")"
      ],
      "metadata": {
        "id": "HfJRdGHesMwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üïµüèª Define your agents\n",
        "\n",
        "# Agent Definitions\n",
        "\n",
        "agent_1 = Agent(\n",
        "    role=dedent((\n",
        "        f\"\"\"\n",
        "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
        "        \"\"\")),\n",
        "    backstory=dedent((\n",
        "        f\"\"\"\n",
        "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
        "        \"\"\")),\n",
        "    goal=dedent((\n",
        "        f\"\"\"\n",
        "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
        "        \"\"\")),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    # ‚Üë Whether the agent execution should be in verbose mode\n",
        "    max_iter=3,\n",
        "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer\n",
        "    llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0.8)\n",
        "    # ‚Üë uncomment to use OpenAI API + \"gpt-4\"\n",
        "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
        "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
        "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
        "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
        "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
        "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
        ")\n",
        "\n",
        "agent_2 = Agent(\n",
        "    role=dedent((\n",
        "        f\"\"\"\n",
        "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
        "        \"\"\")),\n",
        "    backstory=dedent((\n",
        "        f\"\"\"\n",
        "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
        "        \"\"\")),\n",
        "    goal=dedent((\n",
        "        f\"\"\"\n",
        "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
        "        \"\"\")),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    # ‚Üë Whether the agent execution should be in verbose mode\n",
        "    max_iter=3,\n",
        "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer\n",
        "    llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0.8)\n",
        "    # ‚Üë uncomment to use OpenAI API + \"gpt-4\"\n",
        "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
        "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
        "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
        "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
        "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
        "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
        ")\n",
        "\n",
        "agent_3 = Agent(\n",
        "    role=dedent((\n",
        "        f\"\"\"\n",
        "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
        "        \"\"\")),\n",
        "    backstory=dedent((\n",
        "        f\"\"\"\n",
        "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
        "        \"\"\")),\n",
        "    goal=dedent((\n",
        "        f\"\"\"\n",
        "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
        "        \"\"\")),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    # ‚Üë Whether the agent execution should be in verbose mode\n",
        "    max_iter=3,\n",
        "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer\n",
        "    llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0.8)\n",
        "    # ‚Üë uncomment to use OpenAI API + \"gpt-4\"\n",
        "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
        "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
        "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
        "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
        "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
        "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
        ")"
      ],
      "metadata": {
        "id": "hZJwUoXasrhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üìù Define your tasks\n",
        "# Task Definitions\n",
        "\n",
        "task_1 = Task(\n",
        "    description=dedent((\n",
        "        f\"\"\"\n",
        "        A clear, concise statement of what the task entails.\n",
        "        ---\n",
        "        VARIABLE 1: \"{var_1}\"\n",
        "        VARIABLE 2: \"{var_2}\"\n",
        "        VARIABLE 3: \"{var_3}\"\n",
        "        Add more variables if needed...\n",
        "        \"\"\")),\n",
        "    expected_output=dedent((\n",
        "        f\"\"\"\n",
        "        A detailed description of what the task's completion looks like.\n",
        "        \"\"\")),\n",
        "  agent=agent_1,\n",
        ")\n",
        "\n",
        "task_2 = Task(\n",
        "    description=dedent((\n",
        "        f\"\"\"\n",
        "        A clear, concise statement of what the task entails.\n",
        "        ---\n",
        "        VARIABLE 1: \"{var_1}\"\n",
        "        VARIABLE 2: \"{var_2}\"\n",
        "        VARIABLE 3: \"{var_3}\"\n",
        "        Add more variables if needed...\n",
        "        \"\"\")),\n",
        "    expected_output=dedent((\n",
        "        f\"\"\"\n",
        "        A detailed description of what the task's completion looks like.\n",
        "        \"\"\")),\n",
        "    agent=agent_2,\n",
        "    context=[task_1],\n",
        "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
        ")\n",
        "\n",
        "task_3 = Task(\n",
        "    description=dedent((\n",
        "        f\"\"\"\n",
        "        A clear, concise statement of what the task entails.\n",
        "        ---\n",
        "        VARIABLE 1: \"{var_1}\"\n",
        "        VARIABLE 2: \"{var_2}\"\n",
        "        VARIABLE 3: \"{var_3}\"\n",
        "        Add more variables if needed...\n",
        "        \"\"\")),\n",
        "    expected_output=dedent((\n",
        "        f\"\"\"\n",
        "        A detailed description of what the task's completion looks like.\n",
        "        \"\"\")),\n",
        "    agent=agent_3,\n",
        "    context=[task_2],\n",
        "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
        ")"
      ],
      "metadata": {
        "id": "dqtn3w1qs-Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Get your crew to work!\n",
        "def main():\n",
        "    # Instantiate your crew with a sequential process\n",
        "    crew = Crew(\n",
        "        agents=[agent_1, agent_2, agent_3],\n",
        "        tasks=[task_1, task_2, task_3],\n",
        "        verbose=2,  # You can set it to 1 or 2 to different logging levels\n",
        "        # ‚Üë indicates the verbosity level for logging during execution.\n",
        "        process=Process.sequential\n",
        "        # ‚Üë the process flow that the crew will follow (e.g., sequential, hierarchical).\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(dedent(f\"\"\"\\n\\n########################\"\"\"))\n",
        "    print(dedent(f\"\"\"## Here is your custom crew run result:\"\"\"))\n",
        "    print(dedent(f\"\"\"########################\\n\"\"\"))\n",
        "    print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "nrBn8dMlxfCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}